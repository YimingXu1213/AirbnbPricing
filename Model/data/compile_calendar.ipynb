{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scalable data analytics: dask.\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# For GC large pandas dataframes after use.\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'boston'\n",
    "date_boston = ['20181011','20181117','20181213','20190117','20190209','20190312',\n",
    "               '20190415','20190519','20190614','20190714','20190819','20190922',\n",
    "               '20191011']\n",
    "df_boston = pd.DataFrame()\n",
    "for i,date in enumerate(date_boston[:-1]):\n",
    "    filepath = city+'/calendar'+date+'.csv'\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.date = df.date.apply(lambda x: int(x[0:4]+x[5:7]+x[8:]))\n",
    "    df = df[df.date < int(date_boston[i+1])][['listing_id','date','available','price']]\n",
    "    df_boston = pd.concat([df_boston, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'cambridge'\n",
    "date_cambridge = ['20181118','20181215','20190122','20190213','20190318',\n",
    "                  '20190418','20190523','20190624','20190720','20190828','20190925',\n",
    "                  '20191118'] # missing 201810 data\n",
    "df_cambridge = pd.DataFrame()\n",
    "for i,date in enumerate(date_cambridge[:-1]):\n",
    "    filepath = city+'/calendar'+date+'.csv'\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.date = df.date.apply(lambda x: int(x[0:4]+x[5:7]+x[8:]))\n",
    "    df = df[df.date < int(date_cambridge[i+1])][['listing_id','date','available','price']]\n",
    "    df_cambridge = pd.concat([df_cambridge, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df_cambridge.date.min() == int(date_cambridge[0]))\n",
    "assert (df_cambridge.date.max() == int(date_cambridge[-1])-1)\n",
    "assert (df_boston.date.min() == int(date_boston[0]))\n",
    "assert (df_boston.date.max() == int(date_boston[-1])-1)\n",
    "\n",
    "assert sum(df_cambridge.duplicated(subset=['listing_id','date'])) == 0\n",
    "assert sum(df_boston.duplicated(subset=['listing_id','date'])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cambridge['city'] = 'cambridge'\n",
    "# df_boston['city'] = 'boston'\n",
    "df_compiled = pd.concat([df_cambridge, df_boston], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listing_id    0.000000\n",
      "date          0.000000\n",
      "available     0.000000\n",
      "price         0.146957\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# only 'price' contains NaN; drop these rows\n",
    "print(np.mean(df_compiled.isna()))\n",
    "df_compiled = df_compiled.dropna()\n",
    "assert np.sum(np.sum(df_compiled.isna())) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when handling duplicated <lisitng_id, date>, \n",
    "# prioritize unavailable and take mean price\n",
    "df_compiled['unavailable'] = df_compiled.available.apply(lambda x: 0 if x=='t' else 1)\n",
    "df_compiled.price = df_compiled.price.apply(lambda x: float(x[1:].replace(',','')))\n",
    "df_compiled = df_compiled.groupby(['listing_id','date']).agg({'price':'mean','unavailable':'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "df_compiled.to_csv('calendar_compiled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
